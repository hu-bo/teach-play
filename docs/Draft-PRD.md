# TeachPlay

## 目标

一套完整、可扩展、可学习、可编辑、可复用 的 “游戏自动化：教学录制 + 学习识别 + 智能决策” 系统方案


## 核心要求：逐条映射你的需求

 1. 教学录制模式(Record Mode): 启动教学 → 用户操作 → 提取点击区域的信息并记录 -> 生成路径配置文件(json)
 2. 自动执行(Play Mode): 执行配置文件(json) -> 智能node or 固定node -> AI根据OCR提取的信息决策 or 固定点击/滑动 执行
 3. 后台管理端：按项目管理录制文件列表、图片资源、执行步骤node编辑, 可将某个node设置为AI节点，AI根据用户设置的prompt + OCR提取的信息决策改选择哪个按钮，当执行到该节点时，需要从全窗口的多媒体流帧中提取有用的信息判断坐标位置

## 详细系统设计

1. 实时图像捕获（DXGI）, 补充MAC端方案？跨平台（Windows / macOS）
2. 录制步骤时：非文本点击区域点击时 → 自动记录周边元素(优先 OCR识别文本 -> 点击坐标自动截图)，录制同时记录点击、滚顶、拖动等事件及坐标
3. 录制步骤记录为json，上传到minio
4. 文件存储方案：docker 部署 minio 
5. OCR可以考虑PaddleOCR，或者轻量的大模型
6. 执行时，如果是只有截图，则用相似度匹配，如果有文字，则按文字去检索坐标。(录制时会记录坐标，可以用于加速检索区域)
7. 执行时，需要兼容异步操作，比如中途调用AI的接口作决策
8. UI界面/管理端：Tauri + React。功能包含：创建项目、项目列表->录制步骤列表(执行、编辑、删除)、开始录制、停止录制。编辑包含，编辑每个录制步骤的节点，比如某个点击，改为"mode": "ai_decision",由AI决策。并设置prompt
9. 开始录制：需要支持选择所有窗口，展示窗口的缩略图并选择，也可选择全屏模式

案例1(web):
1. 新建录制
2. 打开chrome，输入网址，输入文字、滚动、点击上传文件(需要精确记录具体路径)
案例2(电脑端微信小游戏)
1.  新建录制
2. 打开微信
3. 搜索 “向僵尸开炮”
4. 用户点击“向僵尸开炮”(需要自动记录点击时的区域截图)
5. 点击开始游戏(需要自动记录点击时的区域截图)
6. 出现三张卡片时选择其中一张(后期人工编辑节点时改为，等待节点并通过OCR识别图片中的文字，让AI决策执行时改选哪个)
7. 游戏结束(结束录制)

录制结束后添加等待节点(手动上传结束画面)


模块：
客户端： Tauri + React 管理界面
services： python FastAPI
sdk： recorder-sdk、playback-sdk、ocr-adapter、ai-decision-core
deploy：docker-compose.yml 
storage： minio